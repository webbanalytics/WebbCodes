library(tidyverse)
library(tidytext)
library(lubridate)
library(stringr)
library(httr)
library(dplyr)
library(rtweet)
library(RColorBrewer)
library(wordcloud)
library(rtweet)
rt <- stream_tweets(c('peterborough', 'Hamilton'))
rt <- search_tweets(
c('peterborough', 'Hamilton'), n = 18000, include_rts = FALSE
)
rt
rt <- search_tweets(
'peterborough hamilton', n = 18000, include_rts = FALSE
)
View(rt)
rt <- search_tweets(
c('peterborough','hamilton'), n = 18000, include_rts = FALSE
)
rt <- search_tweets(
'peterborough', n = 18000, include_rts = FALSE
)
View(rt)
library(ddplyr)
library(dplyr)
rt %>%
summarize(n_distinct(screen_name))
rt <- search_tweets(
'ptbo', n = 18000, include_rts = FALSE
)
View(rt)
rt %>%
summarize(n_distinct(screen_name))
tweets_desc <- data_frame(line = 1:1500, text=cb$description)
tweets_desc <- data_frame(line = 1:1500, text=rt$description)
reg_words <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"
library(ggthemes)
ggplot(rt, aes(x = created_at)) +
geom_freqpoly(bins = 20, color = 'blue') +
ylab("Number of Tweets") +
xlab("Date") +
scale_color_ptol("cyl") +
theme_minimal()
tidy_tweets_desc <- tweets_desc %>%
distinct(text) %>%
mutate(text = str_replace_all(text, "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https", "")) %>%
unnest_tokens(word, text, token = "regex", pattern = reg_words) %>%
filter(!word %in% stop_words$word,
str_detect(word, "[a-z]")) %>%
filter(!word %in% c('beer')) %>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, colors = 'navy', n, max.words = 100))
tidy_tweets_desc <- tweets_desc %>%
distinct(text) %>%
mutate(text = str_replace_all(text, "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https", "")) %>%
unnest_tokens(word, text, token = "regex", pattern = reg_words) %>%
filter(!word %in% stop_words$word,
str_detect(word, "[a-z]")) %>%
filter(!word %in% c('peterborough')) %>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, colors = 'navy', n, max.words = 100))
tidy_tweets_desc <- tweets_desc %>%
distinct(text) %>%
mutate(text = str_replace_all(text, "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https", "")) %>%
unnest_tokens(word, text, token = "regex", pattern = reg_words) %>%
filter(!word %in% stop_words$word,
str_detect(word, "[a-z]")) %>%
filter(!word %in% c('peterborough')) %>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, colors = 'navy', n, max.words = 100))
rth <- search_tweets(
'HamOnt', n = 18000, include_rts = FALSE
)
rth <- search_tweets(
'HamOnt', n = 18000, include_rts = FALSE
)
View(rth)
rth %>%
summarize(n_distinct(screen_name))
tweets_desc <- data_frame(line = 1:1500, text=rt$description)
reg_words <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"
tweets_desc <- data_frame(line = 1:1500, text=rth$description)
tweets_desc <- data_frame(line = 1:4452, text=rth$description)
reg_words <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"
ggplot(rt, aes(x = created_at)) +
geom_freqpoly(bins = 20, color = 'blue') +
ylab("Number of Tweets") +
xlab("Date") +
scale_color_ptol("cyl") +
theme_minimal()
ggplot(rth, aes(x = created_at)) +
geom_freqpoly(bins = 20, color = 'blue') +
ylab("Number of Tweets") +
xlab("Date") +
scale_color_ptol("cyl") +
theme_minimal()
tidy_tweets_desc <- tweets_desc %>%
distinct(text) %>%
mutate(text = str_replace_all(text, "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https", "")) %>%
unnest_tokens(word, text, token = "regex", pattern = reg_words) %>%
filter(!word %in% stop_words$word,
str_detect(word, "[a-z]")) %>%
filter(!word %in% c('peterborough')) %>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, colors = 'navy', n, max.words = 100))
tidy_tweets_desc <- tweets_desc %>%
distinct(text) %>%
mutate(text = str_replace_all(text, "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https", "")) %>%
unnest_tokens(word, text, token = "regex", pattern = reg_words) %>%
filter(!word %in% stop_words$word,
str_detect(word, "[a-z]")) %>%
filter(!word %in% c('hamilton','#hamont')) %>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, colors = 'navy', n, max.words = 100))
tidy_tweets_desc <- tweets_desc %>%
distinct(text) %>%
mutate(text = str_replace_all(text, "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https", "")) %>%
unnest_tokens(word, text, token = "regex", pattern = reg_words) %>%
filter(!word %in% stop_words$word,
str_detect(word, "[a-z]")) %>%
filter(!word %in% c('hamilton','#hamont')) %>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, colors = 'navy', n, max.words = 100))
rt$city <- "Peterborough"
rth$city <- "Hamilton"
tweets <- rbind(rt,rth)
View(tweets)
tweets %>%
unnest_tokens(word,text,to_lower = TRUE)
tweets2 <- tweets %>%
unnest_tokens(word,text,to_lower = TRUE)
head(tweets2$word)
tweetwords <- tweets2 %>%
bind_tf_idf(word, city, n)
tweets2$city <- as.factor(tweets2$city)
table(tweets2$city)
tweetwords <- tweets2 %>%
bind_tf_idf(word, city, n)
summary(tweets2$city)
tweetwords <- tweets2 %>%
na.exclude() %>%
bind_tf_idf(word, city, n)
tweets2 <- tweets %>%
unnest_tokens(word,text,to_lower = TRUE, token = 'tweets')
tweets2$city <- as.factor(tweets2$city)
head(tweets2$word)
tweetwords <- tweets2 %>%
na.exclude() %>%
bind_tf_idf(word, city, n)
tweetwords <- tweets2 %>%
bind_tf_idf(word, city, n)
tweets2 <- tweets %>%
distinct(text) %>%
mutate(text = str_replace_all(text, "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https", "")) %>%
unnest_tokens(word, text, token = "tweets", pattern = reg_words) %>%
filter(!word %in% stop_words$word,
str_detect(word, "[a-z]")) %>%
filter(!word %in% c('hamilton','#hamont', 'peterborough', 'ptbo')) %>%
anti_join(stop_words)
regex
tweets2 <- tweets %>%
distinct(text) %>%
mutate(text = str_replace_all(text, "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https", "")) %>%
unnest_tokens(word, text, token = "regex", pattern = reg_words) %>%
filter(!word %in% stop_words$word,
str_detect(word, "[a-z]")) %>%
filter(!word %in% c('hamilton','#hamont', 'peterborough', 'ptbo')) %>%
anti_join(stop_words)
View(tweets2)
tweets2 <- tweets %>%
#distinct(text) %>%
mutate(text = str_replace_all(text, "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https", "")) %>%
unnest_tokens(word, text, token = "regex", pattern = reg_words) %>%
filter(!word %in% stop_words$word,
str_detect(word, "[a-z]")) %>%
filter(!word %in% c('hamilton','#hamont', 'peterborough', 'ptbo')) %>%
anti_join(stop_words)
remove_reg <- "&amp;|&lt;|&gt;"
tidy_tweets <- tweets %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"))
library(stringr)
tidy_tweets <- tweets %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"))
library(tidytext)
tidy_tweets <- tweets %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"))
tidy_tweets <- tweets %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"))
tidy_tweets <- tweets %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"))
tidy_tweets <- tweets %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_replace(text, remove_reg, "")) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"))
tidy_tweets <- tweets %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_replace(text, remove_reg, "")) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_replace(stop_words$word, "'", ""),
str_detect(word, "[a-z]"))
View(tidy_tweets)
tweets2$city <- as.factor(tweets2$city)
rt$city <- "Peterborough"
rth$city <- "Hamilton"
tweets <- rbind(rt,rth)
tidy_tweets <- tweets %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_replace(text, remove_reg, "")) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_replace(stop_words$word, "'", ""),
str_detect(word, "[a-z]"))
tidy_tweets$city <- as.factor(tidy_tweets$city)
tweetwords <- tidy_tweets %>%
bind_tf_idf(word, city, n)
library(tidyr)
frequency <- tidy_tweets %>%
group_by(city) %>%
count(word, sort = TRUE) %>%
left_join(tidy_tweets %>%
group_by(city) %>%
summarise(total = n())) %>%
mutate(freq = n/total)
frequency
tidy_tweets <- tweets %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_replace(text, remove_reg, "")) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_replace(stop_words$word, "'", ""),
!word %in% c('hamilton','peterborough', '#ptbo', '#hamont', '#hamilton'),
str_detect(word, "[a-z]"))
tidy_tweets$city <- as.factor(tidy_tweets$city)
frequency <- tidy_tweets %>%
group_by(city) %>%
count(word, sort = TRUE) %>%
left_join(tidy_tweets %>%
group_by(city) %>%
summarise(total = n())) %>%
mutate(freq = n/total)
frequency
library(tidyr)
frequency <- frequency %>%
select(city, word, freq) %>%
spread(city, freq) %>%
arrange(Hamilton, Peterborough)
frequency
library(scales)
ggplot(frequency, aes(Hamilton, Peterborough)) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
geom_abline(color = "red")
ggplot(frequency, aes(Hamilton, Peterborough)) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
geom_abline(color = "red")
